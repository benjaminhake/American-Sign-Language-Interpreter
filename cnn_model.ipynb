{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "# import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "# import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# gpu settings\n",
    "# Ref: https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of all the labels we have\n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
    "          'X', 'Y']\n",
    "num_of_image = 500  # we have 100 images for each label\n",
    "image_resolution = 128\n",
    "input_dir_path = './asl_gray/'\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "# read grayscaled images\n",
    "for i in range(len(labels)):\n",
    "    for j in range(num_of_image):\n",
    "        temp_im = cv2.imread(input_dir_path + labels[i] + '/' + labels[i] + str(j) + '.png', cv2.IMREAD_COLOR)\n",
    "        # temp_im = 255*temp_im/np.max(temp_im)\n",
    "        temp_im = cv2.resize(temp_im, (image_resolution, image_resolution))\n",
    "        X_train.append(temp_im)\n",
    "        Y_train.append(i)\n",
    "        \n",
    "# convert to a 1200x24 matrix\n",
    "# where if label = i, then the row have 1 in ith column, and 0 otherwise\n",
    "Y_train = to_categorical(Y_train, num_classes=24)\n",
    "\n",
    "# normalize the data\n",
    "X_train = np.array(X_train) / 255\n",
    "X_train = X_train.reshape(-1, image_resolution, image_resolution, 3)\n",
    "# print(X_train[0].shape)\n",
    "# cross-validation: 9:1\n",
    "X_t, X_v, Y_t, Y_v = train_test_split(X_train, Y_train, test_size=0.3, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                6168      \n",
      "=================================================================\n",
      "Total params: 2,199,384\n",
      "Trainable params: 2,198,872\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The model\n",
    "model = Sequential()\n",
    "# Convolution layers\n",
    "# Layer 1\n",
    "model.add(\n",
    "    Conv2D(filters=32, kernel_size=(5, 5), padding='Same', activation='relu', input_shape=(image_resolution, image_resolution, 3), use_bias=True, strides=(2, 2)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))  # downsampling\n",
    "model.add(Dropout(0.25))  # Dropout reduces overfitting\n",
    "# Layer 2\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu', use_bias=True))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Layer 3\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), padding='Same', activation='relu', use_bias=True))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "#\n",
    "# # Layer 4\n",
    "# model.add(Conv2D(filters=128, kernel_size=(3, 3), padding='Same', activation='relu',use_bias=True))\n",
    "# model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(24, activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# use categorical crossentropy as loss function\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define model parameters\n",
    "epochs = 30\n",
    "batch_size = 40\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "210/210 [==============================] - 6s 18ms/step - loss: 3.3738 - accuracy: 0.0968 - val_loss: 2.6226 - val_accuracy: 0.2269\n",
      "Epoch 2/30\n",
      " 13/210 [>.............................] - ETA: 2s - loss: 2.4851 - accuracy: 0.2483"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ANACONDA\\envs\\env1\\lib\\site-packages\\keras\\callbacks\\callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 3s 16ms/step - loss: 2.2825 - accuracy: 0.3081 - val_loss: 3.5489 - val_accuracy: 0.1325\n",
      "Epoch 3/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.5307 - accuracy: 0.5079 - val_loss: 1.5242 - val_accuracy: 0.5156\n",
      "Epoch 4/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 1.0696 - accuracy: 0.6529 - val_loss: 0.9081 - val_accuracy: 0.7103\n",
      "Epoch 5/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.7633 - accuracy: 0.7544 - val_loss: 0.6873 - val_accuracy: 0.7828\n",
      "Epoch 6/30\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 0.6074 - accuracy: 0.8052 - val_loss: 0.4086 - val_accuracy: 0.8511\n",
      "Epoch 7/30\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 0.4657 - accuracy: 0.8532 - val_loss: 0.3775 - val_accuracy: 0.8828\n",
      "Epoch 8/30\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 0.3732 - accuracy: 0.8778 - val_loss: 0.7084 - val_accuracy: 0.7711\n",
      "Epoch 9/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.3159 - accuracy: 0.8974 - val_loss: 0.4590 - val_accuracy: 0.8525\n",
      "Epoch 10/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.2785 - accuracy: 0.9107 - val_loss: 0.1693 - val_accuracy: 0.9431\n",
      "Epoch 11/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.2408 - accuracy: 0.9253 - val_loss: 0.2663 - val_accuracy: 0.9136\n",
      "Epoch 12/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.2250 - accuracy: 0.9254 - val_loss: 0.3639 - val_accuracy: 0.8847\n",
      "Epoch 13/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.1987 - accuracy: 0.9338 - val_loss: 0.1338 - val_accuracy: 0.9569\n",
      "Epoch 14/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.1795 - accuracy: 0.9420 - val_loss: 0.1663 - val_accuracy: 0.9408\n",
      "Epoch 15/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.1576 - accuracy: 0.9416 - val_loss: 0.1231 - val_accuracy: 0.9611\n",
      "Epoch 16/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.1406 - accuracy: 0.9527 - val_loss: 0.1541 - val_accuracy: 0.9458\n",
      "Epoch 17/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.1320 - accuracy: 0.9519 - val_loss: 0.0812 - val_accuracy: 0.9742\n",
      "Epoch 18/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.1275 - accuracy: 0.9592 - val_loss: 0.1127 - val_accuracy: 0.9622\n",
      "Epoch 19/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.1208 - accuracy: 0.9575 - val_loss: 0.1235 - val_accuracy: 0.9625\n",
      "Epoch 20/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.1168 - accuracy: 0.9611 - val_loss: 0.1285 - val_accuracy: 0.9556\n",
      "Epoch 21/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.0963 - accuracy: 0.9704 - val_loss: 0.0816 - val_accuracy: 0.9733\n",
      "Epoch 22/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.1022 - accuracy: 0.9652 - val_loss: 0.1122 - val_accuracy: 0.9622\n",
      "Epoch 23/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.0895 - accuracy: 0.9736 - val_loss: 0.0889 - val_accuracy: 0.9694\n",
      "Epoch 24/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.0968 - accuracy: 0.9660 - val_loss: 0.0837 - val_accuracy: 0.9717\n",
      "Epoch 25/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.0910 - accuracy: 0.9684 - val_loss: 0.0660 - val_accuracy: 0.9781\n",
      "Epoch 26/30\n",
      "210/210 [==============================] - 3s 16ms/step - loss: 0.0845 - accuracy: 0.9707 - val_loss: 0.1051 - val_accuracy: 0.9650\n",
      "Epoch 27/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.0840 - accuracy: 0.9722 - val_loss: 0.0990 - val_accuracy: 0.9664\n",
      "Epoch 28/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.0849 - accuracy: 0.9690 - val_loss: 0.0573 - val_accuracy: 0.9822\n",
      "Epoch 29/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.0748 - accuracy: 0.9763 - val_loss: 0.0762 - val_accuracy: 0.9717\n",
      "Epoch 30/30\n",
      "210/210 [==============================] - 3s 15ms/step - loss: 0.0864 - accuracy: 0.9718 - val_loss: 0.0626 - val_accuracy: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2556c3663c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_t, Y_t, batch_size=batch_size, epochs=epochs, validation_data=(X_v,Y_v), callbacks=[learning_rate_reduction])\n",
    "# final = model.fit(X_train2, Y_train2, batch_size=batch_size, epochs=epochs, validation_data=(X_val,Y_val), callbacks=[learning_rate_reduction])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = './asl_alphabet_test/'\n",
    "X_test = []\n",
    "Y_test = []\n",
    "for i in range(len(labels)):\n",
    "    temp_im = cv2.imread(test_path + labels[i] +'_test.jpg')\n",
    "    temp_im = cv2.resize(temp_im, (image_resolution, image_resolution))\n",
    "    X_test.append(temp_im)\n",
    "    Y_test.append(i)\n",
    "\n",
    "Y_test = to_categorical(Y_test, num_classes=24)\n",
    "\n",
    "# normalize the data\n",
    "X_test = np.array(X_test) / 255\n",
    "X_test = X_test.reshape(-1, image_resolution, image_resolution, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 147ms/step - loss: 3.5741e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00035740784369409084, 1.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get CNN loss and test error\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1afa3090a090>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history['accuracy'])\n",
    "plt.plot(model.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Epochs')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.legend(['Train, Validation'], loc = 'best')\n",
    "plt.show()\n",
    "plt.plot(model.history['loss'])\n",
    "plt.plot(model.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Trian', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "json_mod = model.to_json()\n",
    "with open('cnn_model_500im_epoch30_batch40_layer3_RGB_reshape.json', 'w') as file:\n",
    "    file.write(json_mod)\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
